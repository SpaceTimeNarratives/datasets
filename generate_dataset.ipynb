{"cells":[{"cell_type":"markdown","metadata":{"id":"aUojVOiIhoEv"},"source":["# Generating the working dataset from the CLDW"]},{"cell_type":"markdown","source":["#### **Generating the working dataset from the CLDW**"],"metadata":{"id":"BeekYuvbb_Py"}},{"cell_type":"markdown","source":["Clone (download) the `datasets` repo"],"metadata":{"id":"7SvvHlbhn_Dk"}},{"cell_type":"code","source":["!git clone https://github.com/SpaceTimeNarratives/datasets.git"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"y2yx1lkDbvvc","executionInfo":{"status":"ok","timestamp":1682489894350,"user_tz":-60,"elapsed":1409,"user":{"displayName":"Ignatius Ezeani","userId":"00944355542181313663"}},"outputId":"bcd84f04-9493-4178-e1fe-e6e5b598c38e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'datasets'...\n","remote: Enumerating objects: 16, done.\u001b[K\n","remote: Counting objects: 100% (16/16), done.\u001b[K\n","remote: Compressing objects: 100% (14/14), done.\u001b[K\n","remote: Total 16 (delta 2), reused 12 (delta 1), pack-reused 0\u001b[K\n","Unpacking objects: 100% (16/16), 4.70 MiB | 12.52 MiB/s, done.\n"]}]},{"cell_type":"markdown","source":["Change into the `datasets` directory"],"metadata":{"id":"JCtPqAp-oPpv"}},{"cell_type":"code","source":["cd datasets"],"metadata":{"id":"RBMnxjQkb6M_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1682489894351,"user_tz":-60,"elapsed":6,"user":{"displayName":"Ignatius Ezeani","userId":"00944355542181313663"}},"outputId":"4f40686d-ca8b-4ca2-db72-1211b8373cb5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/datasets\n"]}]},{"cell_type":"markdown","source":["Import necessary files"],"metadata":{"id":"u63FMJAxoZsl"}},{"cell_type":"code","source":["import os\n","import re\n","import string\n","import nltk\n","import shutil\n","import spacy\n","import pandas as pd\n","from bs4 import BeautifulSoup\n","from nltk.tokenize import word_tokenize\n","from nltk.stem import WordNetLemmatizer\n","from nltk.corpus import stopwords\n","nltk.download('wordnet')\n","nltk.download('punkt')\n","lemma = WordNetLemmatizer()"],"metadata":{"id":"_4FvxxLacra3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1682489913951,"user_tz":-60,"elapsed":19603,"user":{"displayName":"Ignatius Ezeani","userId":"00944355542181313663"}},"outputId":"04e2f183-e825-48f2-9cad-d37429cc8144"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"]}]},{"cell_type":"markdown","source":["Extract the CLDW zipped file "],"metadata":{"id":"XAzLyZWuodi9"}},{"cell_type":"code","source":["data_dir = \"LD80 - Full LD Corpus with geoparsing (v5)\"\n","shutil.unpack_archive(f\"{data_dir}.zip\")"],"metadata":{"id":"YNj4wAgTn7TC"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Setting up the extraction pipeline"],"metadata":{"id":"JUeu_hBoBvou"}},{"cell_type":"code","source":["pip -q install -r requirements.txt"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UYXs-s6ODqET","executionInfo":{"status":"ok","timestamp":1682489937695,"user_tz":-60,"elapsed":10445,"user":{"displayName":"Ignatius Ezeani","userId":"00944355542181313663"}},"outputId":"3d4dfded-8c8e-479f-e31d-aa6b32a86d21"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m917.6/917.6 kB\u001b[0m \u001b[31m43.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m83.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m769.7/769.7 kB\u001b[0m \u001b[31m60.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m109.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m668.8/668.8 kB\u001b[0m \u001b[31m56.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.9/51.9 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.5/97.5 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","inflect 6.0.4 requires pydantic>=1.9.1, but you have pydantic 1.8.2 which is incompatible.\n","en-core-web-sm 3.5.0 requires spacy<3.6.0,>=3.5.0, but you have spacy 3.3.1 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0m"]}]},{"cell_type":"code","source":["%run functions.py"],"metadata":{"id":"v-GKunKGDiMK","colab":{"base_uri":"https://localhost:8080/","height":542},"executionInfo":{"status":"error","timestamp":1682511284312,"user_tz":-60,"elapsed":755,"user":{"displayName":"Ignatius Ezeani","userId":"00944355542181313663"}},"outputId":"2ba9178c-8cd4-419f-8074-5eba368b0b7c"},"execution_count":7,"outputs":[{"output_type":"error","ename":"Exception","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, parameter_s, runner, file_finder)\u001b[0m\n\u001b[1;32m    713\u001b[0m             \u001b[0mfpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg_lst\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 714\u001b[0;31m             \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile_finder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    715\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/IPython/utils/path.py\u001b[0m in \u001b[0;36mget_py_filename\u001b[0;34m(name, force_win32)\u001b[0m\n\u001b[1;32m    108\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'File `%r` not found.'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mOSError\u001b[0m: File `'functions.py'` not found.","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-7-bda7ee3663eb>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'run'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'functions.py'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_line_magic\u001b[0;34m(self, magic_name, line, _stack_depth)\u001b[0m\n\u001b[1;32m   2416\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'local_ns'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_local_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2417\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2418\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2419\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2420\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<decorator-gen-52>\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, parameter_s, runner, file_finder)\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, parameter_s, runner, file_finder)\u001b[0m\n\u001b[1;32m    723\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'nt'\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr\"^'.*'$\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    724\u001b[0m                 \u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'For Windows, use double quotes to wrap a filename: %run \"mypath\\\\myfile.py\"'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 725\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    726\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mfpath\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeta_path\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mException\u001b[0m: File `'functions.py'` not found."]}]},{"cell_type":"code","source":["# Get the list of placenames and geonouns\n","place_names = [name.strip().title().replace(\"'S\", \"'s\") for name in open('LD_placenames.txt').readlines()] #read and convert to title case \n","place_names += [name.upper() for name in place_names] #retain the upper case versions\n","geonouns = get_inflections([noun.strip() for noun in open('geo_feature_nouns.txt').readlines()])\n","\n","# Get the list of positive and negative words from the sentiment lexicon\n","pos_words = [w.strip() for w in open('positive-words.txt','r', encoding='latin-1').readlines()[35:]]\n","neg_words = [w.strip() for w in open('negative-words.txt','r', encoding='latin-1').readlines()[35:]]\n","\n","# Create a blank spacy English model\n","nlp = spacy.blank(\"en\")\n","ruler = nlp.add_pipe(\"entity_ruler\")\n","\n","# Define the patterns for the EntityRuler by labelling all the names with the tag PLNAME\n","patterns = [{\"label\": \"PLNAME\", \"pattern\": plname} for plname in set(place_names)]\n","patterns += [{\"label\": \"GEONOUN\", \"pattern\": noun} for noun in geonouns]\n","patterns += [{\"label\": \"+EMOTION\", \"pattern\": word} for word in pos_words]\n","patterns += [{\"label\": \"-EMOTION\", \"pattern\": word} for word in neg_words]\n","\n","ruler.add_patterns(patterns)"],"metadata":{"id":"pDSCdWwdBe8L"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Extract and tag the paragraphs"],"metadata":{"id":"kNq2jX1nEI1a"}},{"cell_type":"code","source":["from spacy import displacy\n","options = {'colors':BG_COLOR}"],"metadata":{"id":"UHSYKJGoEsFZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Define the `get_paragraph()` function that cleans the text and returns a list of text paragraphs"],"metadata":{"id":"UzIJEoWGykjn"}},{"cell_type":"code","source":["def get_paragraphs(input_text):\n","  paragraphs = []\n","  soup = BeautifulSoup(input_text, 'html.parser')\n","  \n","  # Define a regular expression pattern to match XML tags\n","  pattern = re.compile(r'<.*?>')\n","\n","  for i, p in enumerate(soup.find_all('p')):\n","    # Use the sub() function to remove all tags from the XML text\n","    _text = re.sub(pattern, '', str(p))\n","\n","    # use the nltk sentence tokenizer to segment the text into sentences\n","    _text = _text.replace('\\n', ' '\n","              ).replace('\\t', ' '\n","                  ).replace('∫', 's'\n","                      ).replace(\"\\'\", \"'\")\n","\n","    # Replace multiple spaces with one space\n","    paragraphs.append(re.sub(r'\\s+', ' ', _text))\n","\n","  # Split into sentences, strip leading and trailing non-printables and return \n","  return paragraphs"],"metadata":{"id":"svzxNeybW5n5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Build the `data` dictionary by\n","1. Reading all files in the `gold_standard\\` folder\n","2. Applying the `get_paragraphs()` function to return the paragraphs in each file.\n","3. For each paragragh, store the `paraId`, `text`,  and `word_count`"],"metadata":{"id":"K_R2D4-yyyFB"}},{"cell_type":"code","source":["paragraphs = []\n","for fileId, filename in enumerate(sorted(os.listdir('gold_standard'))):\n","  text = open(f'gold_standard/{filename}', 'r', encoding='utf8').read()\n","  for paraId, paragraph in enumerate(get_paragraphs(text)):\n","    paragraphs.append({'fileId':fileId,'paraId':paraId, 'text':paragraph, 'word_count':len(paragraph.split())})"],"metadata":{"id":"jam_8x_VcMyC","colab":{"base_uri":"https://localhost:8080/","height":281},"executionInfo":{"status":"error","timestamp":1682465165251,"user_tz":-60,"elapsed":266,"user":{"displayName":"Ignatius Ezeani","userId":"00944355542181313663"}},"outputId":"31afce0b-7f9c-4618-9948-a7680b268413"},"execution_count":null,"outputs":[{"output_type":"error","ename":"IsADirectoryError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mIsADirectoryError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-13-9371bd1f1bfe>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mparagraphs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfileId\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'gold_standard'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'gold_standard/{filename}'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'utf8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mparaId\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparagraph\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_paragraphs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mparagraphs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'fileId'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mfileId\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'paraId'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mparaId\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'text'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mparagraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'word_count'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparagraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mIsADirectoryError\u001b[0m: [Errno 21] Is a directory: 'gold_standard/LD80 - Full LD Corpus with geoparsing (v5)'"]}]},{"cell_type":"markdown","source":["Convert it to a Pandas dataframe for viewing"],"metadata":{"id":"spayx3zF2Gvc"}},{"cell_type":"code","source":["data = pd.DataFrame.from_dict(paragraphs)\n","data"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":423},"id":"s8t9eJB4gYef","executionInfo":{"status":"ok","timestamp":1682374110538,"user_tz":-60,"elapsed":209,"user":{"displayName":"Ignatius Ezeani","userId":"00944355542181313663"}},"outputId":"cd03e29c-dd2a-4702-ed51-570e07487d06"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["      fileId  paraId                                               text  \\\n","0          0       0  By the route which we have traced among the En...   \n","1          0       1  With the carefully prepared map attached to th...   \n","2          0       2  At all seasons the scenery of the lake distric...   \n","3          0       3  This is a clean-looking ancient town in the so...   \n","4          0       4  From Penrith two roads lead to Pooley Bridge, ...   \n","...      ...     ...                                                ...   \n","1739      27     179  The following sketches of farms will give an i...   \n","1740      27     180                                           Another,   \n","1741      27     181                                           Another,   \n","1742      27     182                                           Another,   \n","1743      27     183  Lancaster is a flourishing town, well situated...   \n","\n","      word_count  \n","0            112  \n","1            631  \n","2             68  \n","3            122  \n","4             89  \n","...          ...  \n","1739          13  \n","1740           1  \n","1741           1  \n","1742           1  \n","1743          98  \n","\n","[1744 rows x 4 columns]"],"text/html":["\n","  <div id=\"df-ddff66e3-7303-4d08-b2e6-a1c6545b4aa9\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>fileId</th>\n","      <th>paraId</th>\n","      <th>text</th>\n","      <th>word_count</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>By the route which we have traced among the En...</td>\n","      <td>112</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>With the carefully prepared map attached to th...</td>\n","      <td>631</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>At all seasons the scenery of the lake distric...</td>\n","      <td>68</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>This is a clean-looking ancient town in the so...</td>\n","      <td>122</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0</td>\n","      <td>4</td>\n","      <td>From Penrith two roads lead to Pooley Bridge, ...</td>\n","      <td>89</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>1739</th>\n","      <td>27</td>\n","      <td>179</td>\n","      <td>The following sketches of farms will give an i...</td>\n","      <td>13</td>\n","    </tr>\n","    <tr>\n","      <th>1740</th>\n","      <td>27</td>\n","      <td>180</td>\n","      <td>Another,</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1741</th>\n","      <td>27</td>\n","      <td>181</td>\n","      <td>Another,</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1742</th>\n","      <td>27</td>\n","      <td>182</td>\n","      <td>Another,</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1743</th>\n","      <td>27</td>\n","      <td>183</td>\n","      <td>Lancaster is a flourishing town, well situated...</td>\n","      <td>98</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1744 rows × 4 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ddff66e3-7303-4d08-b2e6-a1c6545b4aa9')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-ddff66e3-7303-4d08-b2e6-a1c6545b4aa9 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-ddff66e3-7303-4d08-b2e6-a1c6545b4aa9');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":203}]},{"cell_type":"markdown","source":["Update the `data` dictionary. For each file\n","1. Go through all the paragraphs\n","2. Extract all PLNAMES and GEONOUNS. +/-EMOTIONS\n","3. Store the list of each tags as well as the counts"],"metadata":{"id":"m7ySOPCtz5JV"}},{"cell_type":"code","source":["def pre_process_text(text):\n","  return list(filter(lambda token: token not in string.punctuation,\n","             [lemma.lemmatize(word) for word in word_tokenize(text) \n","             if word.lower() not in stop_words]))\n","# Get entity counts for each tag\n","def get_entities(text, tag):\n","  return [(ent, ent.start_char, ent.end_char) for ent in nlp(text).ents if ent.label_ == tag]\n","  \n","def add_entity_count(data_df, tag):\n","  ents = [get_entities(text, tag) for text in data_df['text']]\n","  counts = [len(count) for count in ents]\n","  return ents, counts\n","\n","data['plnames'], data['pn_cnts'] = add_entity_count(data, 'PLNAME')\n","data['geonouns'], data['gn_cnts'] = add_entity_count(data, 'GEONOUN')\n","data['pos_emotions'], data['pos_cnts'] = add_entity_count(data, '+EMOTION')\n","data['neg_emotions'], data['neg_cnts'] = add_entity_count(data, '-EMOTION')\n","data['sentiment_score'] = (data['pos_cnts'] - data['neg_cnts'])/data['text'].apply(lambda x : len(pre_process_text(x)))"],"metadata":{"id":"0NIudNLZZTPo"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["List all occurences of entities (place names, geonouns, emotions) with their file and paragraph IDs"],"metadata":{"id":"ZeqMm4UhRY2K"}},{"cell_type":"code","source":["# Define the `add_tag` function to attach the tag to each entity from a given list\n","add_tag = lambda x_list, tag: [(x,tag) for x in x_list]"],"metadata":{"id":"nX5462hSVULy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["entities_df = data[['plnames','geonouns', 'pos_emotions', 'neg_emotions','fileId', 'paraId']]\n","ent_list = []\n","for i in range(len(entities_df)): \n","  plns, gns, pos, neg, fId, pId = entities_df.iloc[i]\n","  ents = add_tag(plns,'PLNAME')+add_tag(gns,'GEONOUN')+add_tag(pos,'+EMOTION'\n","                                                  ) + add_tag(neg, '-EMOTION')\n","  if ents:\n","    for ent, tag in ents:\n","      ent_list.append({'entity': ent[0], 'start_char':ent[1], 'end_char':ent[2], \n","                      'fileId':fId, 'paraId':pId, 'tag':tag})\n","ent_list_df = pd.DataFrame.from_dict(ent_list)\n","ent_list_df"],"metadata":{"id":"NjXBcuq_CTXe"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Convert it to Excel for export"],"metadata":{"id":"xS5eGbCWFDF5"}},{"cell_type":"code","source":["with pd.ExcelWriter('paragraph_counts_v0.xlsx') as writer:  \n","    data.to_excel(writer, sheet_name='paragraphs')\n","    ent_list_df.to_excel(writer, sheet_name='all entities')"],"metadata":{"id":"zybVWRFsFKjp"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"collapsed_sections":["iZ0kCbYUh4gu","jOdjjJwFHv11","vb8f7aoPsYgL","bgHhZlUA20l5","kcWZ_eqy-tGZ","CDxwHd1z_CW1","vBPN4g5R-P0B","VM57tYlXlO2Y","Zw9jVk97R4SB","1tCywxkPi1r2","WwolMngoq_hs"],"provenance":[{"file_id":"1a8NMWYvBRyttBo0jGMw4zc0NFdV17Ycx","timestamp":1682417590715},{"file_id":"https://github.com/IgnatiusEzeani/spatial_narrative_project/blob/main/code/python_script.ipynb","timestamp":1665988104835}]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"}},"nbformat":4,"nbformat_minor":0}